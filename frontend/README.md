# VitalSense AI â€” Frontend

**Professional, production-ready web UI for the rPPG Vital Signs Estimation System.**

Built with React 18, Tailwind CSS, and Lucide Icons â€” zero build step required.

---

## âœ¨ Features

### ğŸ¯ 3-Step User Journey
1. **User Information** â€” Age, gender, height, weight with real-time validation
2. **Face Scanning** â€” Live progress tracking with visual feedback (0â€“100%)
3. **Results Dashboard** â€” Beautiful cards showing HR, HRV, BP, and Stress

### ğŸ¨ UI/UX Highlights
- **Responsive design** â€” Works on mobile, tablet, desktop
- **Real-time progress** â€” Updates every 500ms during scan
- **Animated feedback** â€” Pulsing scan ring, smooth transitions
- **Clear instructions** â€” Step-by-step guidance with icons
- **Error handling** â€” Graceful fallbacks if scan fails or face not detected
- **Industry-standard design** â€” Gradient cards, professional typography, accessibility-friendly

### ğŸ”’ Safety & Validation
- **Form validation** â€” Age (10â€“120), height (100â€“250 cm), weight (20â€“300 kg)
- **API error handling** â€” Clear error messages if backend is down
- **Disclaimers** â€” Prominent warnings that this is NOT a medical device

---

## ğŸš€ Quick Start

### 1. Make sure your backend is running

```bash
cd ../   # Go back to rppg_vitals root
python main.py
```

Backend should be running on `http://localhost:8000`.

### 2. Serve the frontend

**Option A â€” Python (simplest)**

```bash
cd frontend
python -m http.server 3000
```

Then open: **http://localhost:3000**

**Option B â€” Node.js (if you have it)**

```bash
npx serve -s . -p 3000
```

**Option C â€” VS Code Live Server**

Right-click `index.html` â†’ "Open with Live Server"

---

## ğŸ“ File Structure

```
frontend/
â”œâ”€â”€ index.html      # HTML shell with CDN links (React, Tailwind, Lucide)
â”œâ”€â”€ app.jsx         # Main React app (3 steps + API client)
â””â”€â”€ README.md       # This file
```

**Why no build step?**  
We're using CDN-hosted React (via UMD) and Babel Standalone for JSX transpilation. This is perfect for quick prototyping and demos. For production deployment with millions of users, you'd migrate to Vite/Next.js.

---

## ğŸ¨ Customization

### Change Colors

Edit the gradient classes in `index.html` `<style>` block:

```css
.gradient-bg {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  /* â†‘ Change these hex codes */
}
```

### Change Scan Duration

In `app.jsx`, find this line in `Step2_Scanning`:

```javascript
const [scanDuration] = useState(45);  // â† Change to 30, 60, etc.
```

### Change API URL

At the top of `app.jsx`:

```javascript
const API_BASE = 'http://localhost:8000';  // â† Change if backend is on a different port/domain
```

---

## ğŸŒ Deployment

### Deploy to Vercel / Netlify (Free)

1. Create a `netlify.toml` or `vercel.json`:

```toml
# netlify.toml
[[redirects]]
  from = "/*"
  to = "/index.html"
  status = 200
```

2. Push to GitHub

3. Connect repo to Vercel/Netlify â€” it auto-deploys

4. **Important:** Update `API_BASE` in `app.jsx` to your deployed backend URL

### Deploy Backend to Cloud

**Option 1 â€” Render.com (free tier)**

1. Push your `rppg_vitals` repo to GitHub
2. Create a new Web Service on Render
3. Build command: `pip install -r requirements.txt`
4. Start command: `python main.py`
5. Copy the deployed URL (e.g., `https://your-app.onrender.com`)
6. Update `API_BASE` in frontend

**Option 2 â€” Railway / Fly.io / AWS / GCP**

Similar process â€” most have 1-click FastAPI deploy.

---

## ğŸ”§ Troubleshooting

| Issue | Fix |
|-------|-----|
| **"This site can't be reached"** | Make sure you're serving the frontend (`python -m http.server 3000`) and visiting `localhost:3000`, not just opening `index.html` directly in the browser (React needs to be served via HTTP). |
| **"Failed to fetch" errors** | Backend isn't running. Start `python main.py` in the root directory. |
| **CORS errors** | The backend already has CORS enabled for `*`. If you still see errors, restart the backend. |
| **Icons not showing** | Lucide icons are loaded via CDN. Check your internet connection, or download Lucide locally. |
| **Scan stuck at 0%** | See the main README troubleshooting â€” likely a face detection issue. Run `test_camera.py`. |

---

## ğŸ“± Mobile Support

The UI is fully responsive and works on phones. However:

- **Camera access** requires HTTPS in production (localhost works without HTTPS in dev)
- Face detection quality depends on phone camera resolution and lighting
- For best results, use a tablet or laptop

---

## ğŸ¯ Roadmap / Future Enhancements

- [ ] Export results as PDF report
- [ ] Historical tracking (save scans to localStorage or backend database)
- [ ] Comparison charts (show trends over time)
- [ ] Multi-language support (i18n)
- [ ] Dark/light mode toggle
- [ ] Integration with health apps (Apple Health, Google Fit)

---

## ğŸ“„ License

Same as the main project â€” provided as-is for educational, research, and prototyping purposes.

**Remember:** This is a wellness estimation tool, NOT a medical device.
